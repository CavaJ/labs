{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.misc \n",
    "import scipy.io\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 train images loaded\n",
      "18 test images loaded\n",
      "37632 dimensional input\n",
      "2 classes\n"
     ]
    }
   ],
   "source": [
    "# 1. – Load costum dataset and build training and test data tensor\n",
    "\n",
    "# 1.1.  Load cat/dog image data generated by generate_dataset.ipynb\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "loadpath = cwd + \"/data/data4vgg.npz\"\n",
    "l = np.load(loadpath)\n",
    "\n",
    "# See what's in here\n",
    "l.files\n",
    "\n",
    "# Parse data\n",
    "trainimg = l['trainimg']\n",
    "trainlabel = l['trainlabel']\n",
    "testimg = l['testimg']\n",
    "testlabel = l['testlabel']\n",
    "ntrain = trainimg.shape[0]\n",
    "nclass = trainlabel.shape[1]\n",
    "dim    = trainimg.shape[1]\n",
    "ntest  = testimg.shape[0]\n",
    "\n",
    "print (\"%d train images loaded\" % (ntrain))\n",
    "print (\"%d test images loaded\" % (ntest))\n",
    "print (\"%d dimensional input\" % (dim))\n",
    "print (\"%d classes\" % (nclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.2. Make a training_tensor and test_tensor each of which has (n, 112, 112, 3) dimension. np.ndarray, np.reshape\n",
    "\n",
    "training_tensor = np.ndarray((ntrain, 112, 112, 3))\n",
    "\n",
    "# for each training example, reshape it and update training_tensor\n",
    "# we have 69 training images, training tensor dimension will be 69, 112, 112, 3\n",
    "for index in range(ntrain):\n",
    "    img = trainimg[index, :]\n",
    "    img = np.reshape(img, [112, 112, 3])\n",
    "    training_tensor[index, :, :, :] = img \n",
    "    \n",
    "test_tensor = np.ndarray((ntest, 112, 112, 3))\n",
    "\n",
    "# do the same thing for each test example\n",
    "# we have 18 test images, test tensor dimension will be 18, 112, 112, 3\n",
    "for index in range(ntest):\n",
    "    img = testimg[index, :]\n",
    "    img = np.reshape(img, [112, 112, 3])\n",
    "    test_tensor[index, :, :, :] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. – Load pre-trained VGG model as same way in vgg.ipynb\n",
    "\n",
    "# code from vgg.ipynb\n",
    "def net(data_path, input_image):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "    weights = data['layers'][0]\n",
    "\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(layers)\n",
    "    return net, mean_pixel\n",
    "\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Define VGG features as the output of relu5_4\n",
    "\n",
    "def imread(path):\n",
    "    return scipy.misc.imread(path).astype(np.float)\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)\n",
    "        \n",
    "cwd  = os.getcwd()\n",
    "VGG_PATH = cwd + \"/data/imagenet-vgg-verydeep-19.mat\"\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # as given in assignment5.pdf file by default\n",
    "    image_placeholder = tf.placeholder(tf.float32, shape=(None, 112, 112, 3))\n",
    "    net, mean_pixel = net(VGG_PATH, image_placeholder)\n",
    "    train_features = net['relu5_4'].eval(feed_dict={image_placeholder: training_tensor})\n",
    "    test_features = net['relu5_4'].eval(feed_dict={image_placeholder: test_tensor})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. – Construct your fully connected layers on top of the VGG features\n",
    "\n",
    "# 4.1. • You would need to vectorize VGG features to be input of the fc layer\n",
    "# 4.2. • Try to build multiple layers between 7x7x512 dimensional input to 2-dim output\n",
    "\n",
    "training_tensor_vect = np.ndarray((ntrain, 7 * 7 * 512))\n",
    "test_tensor_vect = np.ndarray((ntest, 7 * 7 * 512))\n",
    "\n",
    "# reshape each training feature obtained from relu5_4 layer and update vectorized tensor\n",
    "for index in range(ntrain):\n",
    "    feature = train_features[index, :, :, :]\n",
    "    feature_reshaped = np.reshape(feature, (1, -1))\n",
    "    training_tensor_vect[index, :] = feature_reshaped\n",
    "\n",
    "# reshape each test feature obtained from relu5_4 layer and update vectorized tensor\n",
    "for index in range(ntest):\n",
    "    feature = test_features[index, :, :, :]\n",
    "    feature_reshaped = np.reshape(feature, (1, -1))\n",
    "    test_tensor_vect[index, :] = feature_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. – Training fc layers using your training images. (Fine-tuning)\n",
    "\n",
    "# Parameters\n",
    "learning_rate   = 0.001\n",
    "training_epochs = 50\n",
    "batch_size      = 100\n",
    "display_step    = 10\n",
    "\n",
    "# Fully Connected Layer\n",
    "n_input  = dim\n",
    "n_output  = 2 # cat or dog\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 7 * 7 * 512])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "# keep probability for dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# define weights and biases\n",
    "weights  = {\n",
    "    'wf1': tf.Variable(tf.random_normal([7 * 7 * 512, 1024], stddev=0.1)),\n",
    "    'wf2': tf.Variable(tf.random_normal([1024, n_output], stddev=0.1))\n",
    "}\n",
    "biases   = {\n",
    "    'bf1': tf.Variable(tf.random_normal([1024], stddev = 0.1)),\n",
    "    'bf2': tf.Variable(tf.random_normal([n_output], stddev = 0.1))\n",
    "}\n",
    "\n",
    "# Vectorize\n",
    "dense = tf.reshape(x, [-1, weights['wf1'].get_shape().as_list()[0]])\n",
    "    \n",
    "# layer before output layer\n",
    "before_out = tf.nn.relu(tf.add(tf.matmul(dense, weights['wf1']), biases['bf1']))\n",
    "# apply dropout\n",
    "before_out_drop = tf.nn.dropout(before_out, keep_prob)\n",
    "    \n",
    "# output layer\n",
    "out = tf.add(tf.matmul(before_out_drop, weights['wf2']), biases['bf2'])\n",
    "\n",
    "# Saver \n",
    "save_step = 10;\n",
    "saver = tf.train.Saver(max_to_keep=training_epochs) \n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(out, y))\n",
    "optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(out,1), tf.argmax(y,1)) # Count corrects\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32)) # Accuracy\n",
    "\n",
    "# init all variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/050 cost: 66.911224365\n",
      " Training accuracy: 0.550\n",
      " Test accuracy: 0.222\n",
      "Epoch: 010/050 cost: 2.996534348\n",
      " Training accuracy: 0.830\n",
      " Test accuracy: 0.333\n",
      "Epoch: 020/050 cost: 0.077286795\n",
      " Training accuracy: 0.980\n",
      " Test accuracy: 0.833\n",
      "Epoch: 030/050 cost: 0.000000000\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.889\n",
      "Epoch: 040/050 cost: 0.000000000\n",
      " Training accuracy: 1.000\n",
      " Test accuracy: 0.889\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    num_batch = int(ntrain/batch_size)+1\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch): \n",
    "        randidx = np.random.randint(ntrain, size=batch_size)\n",
    "        batch_xs = training_tensor_vect[randidx, :]\n",
    "        batch_ys = trainlabel[randidx, :]                \n",
    "        # Fit training using batch data\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys, keep_prob:1.})\n",
    "        # Compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob:1.}) / num_batch\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys, keep_prob:1.})\n",
    "        print (\" Training accuracy: %.3f\" % (train_acc))\n",
    "        test_acc = sess.run(accr, feed_dict={x: test_tensor_vect, y: testlabel, keep_prob:1.})\n",
    "        print (\" Test accuracy: %.3f\" % (test_acc))\n",
    "            \n",
    "    # Save Net\n",
    "    if epoch % save_step == 0:\n",
    "        saver.save(sess, \"net/cnn_custom_dataset.ckpt-\" + str(epoch))\n",
    "\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "# 6. I obtained test accuracy of 0.899 which is bigger than 0.833. By playing with dropout we can improve accuracy more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
